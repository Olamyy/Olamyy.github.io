<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width initial-scale=1" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">

  <title>Olamilekan F. Wahab | The Sklearn API Design Principles</title>
  <meta name="description" content="A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design.
">

  

  <link rel="shortcut icon" href="/assets/img/favicon.ico">

  <link rel="stylesheet" href="/assets/css/main.css">
  <link rel="canonical" href="/blog/2018/understanding-the-sklearn-design/">
</head>


  <body>

    <header class="site-header">

  <div class="wrapper">

    
    <span class="site-title">
        
        <strong>Olamilekan</strong> Wahab
    </span>
    

    <nav class="site-nav">
      <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path fill="#424242" d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.031C17.335,0,18,0.665,18,1.484L18,1.484z"/>
              <path fill="#424242" d="M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0c0-0.82,0.665-1.484,1.484-1.484 h15.031C17.335,6.031,18,6.696,18,7.516L18,7.516z"/>
              <path fill="#424242" d="M18,13.516C18,14.335,17.335,15,16.516,15H1.484C0.665,15,0,14.335,0,13.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.031C17.335,12.031,18,12.696,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

      <div class="trigger">
        <!-- About -->
        <a class="page-link" href="/">about</a>

        <!-- Blog -->
        <a class="page-link" href="/blog/">blog</a>

        <!-- Pages -->
        
          
        
          
        
          
        
          
            <a class="page-link" href="/publications/">publications</a>
          
        
          
        

        <!-- CV link -->
        <!-- <a class="page-link" href="/assets/pdf/CV.pdf">vitae</a> -->

      </div>
    </nav>

  </div>

</header>



    <div class="page-content">
      <div class="wrapper">
        <div class="post">

  <header class="post-header">
    <h1 class="post-title">The Sklearn API Design Principles</h1>
    <p class="post-meta">May 5, 2018</p>
  </header>

  <article class="post-content">
    <p>You should read this if:</p>

<ol>
  <li>
    <p>You’ve never really understood how sklearn modules/classes are structured.</p>
  </li>
  <li>
    <p>You’re interested in contributing to sklearn.</p>
  </li>
  <li>
    <p>You need to understand the internals of sklearn, why some decisions were made and how some things work.</p>
  </li>
</ol>

<hr />
<p>Some weeks back, I decided to start contributing to the open source scikit-learn library. This decision led me to read a whole lot of sklearn’s code, documentation , contribution and 
online guides.</p>

<p>This article is an attempt to document everything I learnt about the design principles behind the library.</p>

<p>The rest of the article will be organised as follows:</p>

<ul>
  <li>What is a scikit in python?
    <ul>
      <li>Examples of scikits</li>
    </ul>
  </li>
  <li>Scikit-learn
    <ul>
      <li>What is scikit-learn?</li>
      <li>A little history</li>
      <li>Data representation</li>
      <li>API Design Principles
        <ul>
          <li>Consistency
            <ul>
              <li>Estimators</li>
              <li>Predictors</li>
              <li>Transformers</li>
              <li>Meta-estimators</li>
              <li>Pipelines and Feature Unions</li>
            </ul>
          </li>
          <li>Other Principles</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>Conclusion</li>
  <li>Resources</li>
</ul>

<h2 id="what-is-a-scikit-in-python">What is a scikit in python?</h2>
<p>A scikit, short for SciPy Toolkit(or the more expressive, Scientifica Python Toolkit) is any open sourced software written in Python to supplement Scipy. Scikits are essentially add on 
packages 
that are related to either science, engineering or research in one field or another. They’re usually BSD licensed and are built upon existing libraries like scipy and numpy. A package can be called
a scikit when :</p>

<ol>
  <li>It is too specialized on a field or topic to part of SciPy.</li>
  <li>It is GPL licensed (This makes it incompatible with SciPy’s BSD license).</li>
  <li>It’s meant to be part of Scipy but is still actively being developed.</li>
</ol>

<h3 id="example-of-scikits">Example of scikits</h3>
<p>Some of the most widly used example scikit packages are:</p>

<ol>
  <li>Machine Learning Specific
    <ul>
      <li><a href="http://scikit-learn.org/">Scikit-learn</a></li>
      <li><a href="http://scikits.appspot.com/scikit-neuralnetwork">Scikit-neuralnetwork</a></li>
      <li><a href="http://scikits.appspot.com/scikit-splearn">scikit-splearn</a></li>
      <li><a href="http://scikits.appspot.com/scikit-metrics">scikit-metrics</a></li>
      <li><a href="http://scikits.appspot.com/scikit-tensor">scikit-tensor</a></li>
      <li><a href="http://scikits.appspot.com/scikit-surprise">scikit-surprise</a></li>
      <li><a href="http://scikits.appspot.com/scikit-stack">scikit-stack</a></li>
      <li><a href="http://scikits.appspot.com/scikit-graph">scikit-graph</a></li>
      <li><a href="http://scikits.appspot.com/scikit-keras">scikit-keras</a></li>
    </ul>
  </li>
  <li>Media Specific Scikits
    <ul>
      <li><a href="http://scikits.appspot.com/scikit-image">Scikit-image</a></li>
      <li><a href="http://scikits.appspot.com/scikit-sound">Scikit-sound</a></li>
      <li><a href="http://scikits.appspot.com/scikit-video">Scikit-video</a></li>
      <li><a href="http://scikits.appspot.com/scikit-xray">Scikit-xray</a></li>
    </ul>
  </li>
  <li>Data Specific
    <ul>
      <li><a href="http://scikits.appspot.com/scikit-dataaccess">Scikit-dataacces</a></li>
      <li><a href="http://github.com/pandas/pandas-dev">Pandas</a></li>
      <li><a href="http://scikits.appspot.com/scikit-data">Scikit-data</a></li>
      <li><a href="http://scikits.appspot.com/scikit-datasets">Scikit-datasets</a></li>
      <li><a href="http://scikits.appspot.com/scikit-discovery">Scikit-discovery</a></li>
    </ul>
  </li>
  <li>Visualization Specific Scikits
    <ul>
      <li><a href="">Matplotlib</a></li>
      <li><a href="http://scikits.appspot.com/scikit-visualizations">Scikit-visualizations</a></li>
      <li><a href="http://scikits.appspot.com/scikit-vi">Scikit-vi</a></li>
      <li><a href="http://scikits.appspot.com/scikit-vis">Scikit-vis</a></li>
      <li><a href="http://scikits.appspot.com/scikit-viz">Scikit-viz</a></li>
      <li><a href="http://scikits.appspot.com/scikit-plot">Scikit-plot</a></li>
    </ul>
  </li>
</ol>

<p>While the list above covers some popular scikits, the official <a href="http://scikits.appspot.com/scikits">scikit appspot website</a> links to a whole lot of other scikits.</p>

<h2 id="scikit-learn">Scikit-learn</h2>
<h3 id="what-is-scikit-learn">What is scikit-learn?</h3>
<p>Scikit-learn(shortened as sklearn) is an open source library that provides a consistent API for using traditional state of the art Machine Learning algorithms/methods in Python.</p>

<p>Majorly written in Python, some of sklearn’s internal algorithms are written in Cython using third party bindings like LIBSVM and 
LIBLINEAR. Sklearn’s major python dependencies are scipy, numpy and matplotlib.</p>

<p><img src="/assets/images/sklearn.png" alt="sklearn dependency tree." /></p>

<p>Figure 1 : This shows a dependency tree for the sklearn library.</p>

<h2 id="a-little-history">A little history</h2>
<p>During the Google Summer of Code in 2007, David Cournapeau decided to put together a number of algorithms he has been using over time into a python module. A while after this, Matthieu Brucher joined
the project and decided to use it for computational work in his thesis. This gave sklearn more light and in no time(2010 to be specific), <a href="">INRA</a> got involved in it and the first major release was 
published in the same year.</p>

<h2 id="data-representation">Data Representation</h2>
<p>Machine learning data in different fields, languages, etc. is generally represented as a pair of matrices with numerical values, say $X$ and $y$. The $X$ variables often represent the input values and
the $y$ variables represent the output values. Each row of these matrices  to one sample of the dataset and each column to one variable of the problem.
Sklearn as expected also follows the same form for representing data internally. To represent data, it classifies all data under 3 types of data:</p>

<p>####1. Sparse Data</p>

<p>A sparse data is any dataset that mostly contains more zeros than non-zero entries. To be a bit technical, a vector is $k$-sparse if it contains at most $k$ nonzero entries.</p>

<p><img src="/assets/images/sparse_matrix.png" alt="sparse matrix." /></p>

<p>Figure 2 : An example of a sparse matrix.</p>

<p>Sklearn represents sparse data as scipy sparse matrices. It does this because:</p>

<ul>
  <li>Storing all zero values in a sparse matrix is a computational waste.</li>
  <li>It is much more efficient to operate only on elements that will return nonzero values.</li>
</ul>

<p>To avoid these, sklearn uses a scipy algorithm called Compressed Sparse Row (CSR). This essentially compresses the memory footprint of the matrix object and speeds up insert and retrieval processes
 to optimize the operation of many sklearn’s algorithms.</p>

<blockquote>
  <blockquote>
    <blockquote>
      <p>Sklearn has a number of algorithms that support sparse matrix operations. If you ever need to check if an algorithm supports sparse data, check the documentation of the  <code class="language-plaintext highlighter-rouge">fit</code> method of it’s 
 class. If it has an <code class="language-plaintext highlighter-rouge">X: {array-like, sparse matrix}</code> entry, then it supports sparse data entry.</p>
    </blockquote>
  </blockquote>
</blockquote>

<p>For a much more thorough understanding of how scipy sparse matrices work, you can check out <a href="https://github.com/dziganto/Data_Science_Fundamentals">David Ziganto’s</a> article <a href="https://dziganto.github.io/Sparse-Matrices-For-Efficient-Machine-Learning/">here</a></p>

<p>####2. Dense Data</p>

<p>A dense data contains mostly non-zero entries.</p>

<p><img src="/assets/images/dense.jpg" alt="dense matrix." /></p>

<p>Figure 3 : An example of a dense matrix.</p>

<p>Sklearn represents dense data as  multidimensional numpy arrays.
   <a href="">X’s</a> notes has a very thorough explanation of how this works.</p>

<p>####3. Non standard textual data
For situations where models are to be built using text files or semi-stuctured python objects, sklearn attempts to <code class="language-plaintext highlighter-rouge">vectorize</code> these files/objects into the more efficient numpy and scipy data types.</p>

<h2 id="api-design-principles">API Design Principles</h2>
<p>In this section, I would discuss some of the design desicions that were made during the creation of the library, why they were made and how these decisions have influenced the way the library is 
 used now.</p>

<h3 id="consistency">Consistency</h3>
<p>The sklearn API was majorly designed to be consistent. This means object that do the same things are given a simple and consistent interface. Having a consistent API meant objects(sklearn objects)
 had to be grouped based on a number of conditions.
 The available types of sklearn objects are:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> 1. Estimators and Meta-estimators
 2. Transformers
 3. Predictors
 4. Pipelines
 5. Feature Unions
</code></pre></div></div>

<ol>
  <li>
    <p>Estimators and meta-estimators:</p>

    <p>Estimator objects like you would expect are sklearn classes that estimate parameters in data. Both supervised and unsupervised sklearn algorithms provide support for estimators. Since estimator
 objects do some form of <code class="language-plaintext highlighter-rouge">learning</code>, the initialization and learning phase of estimators are separated.
 If  <code class="language-plaintext highlighter-rouge">hyperparameter</code> values are set during the initialization of estimators, the set values are used during learning. If not, the default values are used while learning.</p>

    <p>Once initialized, estimators expose a <code class="language-plaintext highlighter-rouge">fit</code> method where the estimation learning happens. The <code class="language-plaintext highlighter-rouge">fit</code> method is called with one parameter(or two if the task being handled is a 
 supervised learning task. This parameter is the <code class="language-plaintext highlighter-rouge">label</code> datasets.)  The <code class="language-plaintext highlighter-rouge">fit</code> method when called learns by determining model-specific parameters from the training data and set these as attributes
  on the estimator object. Once learning is complete, this model sets its parameters(the learned parameters) gets exposed as class attributes with trailing underscore in their names(An example 
  is the <code class="language-plaintext highlighter-rouge">statistics_</code> attribute of the <code class="language-plaintext highlighter-rouge">Imputer</code> estimator.).</p>

    <p>In situations where a user needs to implement a custom estimator, the <code class="language-plaintext highlighter-rouge">BaseEstimator</code> 
    class and it’s(the required classifier’s) 
    corresponding 
    <code class="language-plaintext highlighter-rouge">mixin</code> can be 
    subclassed as shown below.</p>

    <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>     <span class="kn">from</span> <span class="nn">sklearn.base</span> <span class="kn">import</span> <span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">RegressorMixin</span>
        
     <span class="c1">## A regressor mixin is being used here because 
</span>     <span class="c1">## the example is for a regressor Estimator.  
</span>    
     <span class="k">class</span> <span class="nc">ExampleRegressorEstimator</span><span class="p">(</span><span class="n">BaseEstimator</span><span class="p">,</span> <span class="n">RegressorMixin</span><span class="p">):</span>  
     <span class="s">"""An example of an regressor estimator. 
     Take a good look at docstring of the constructor, fit and predict methods. """</span>
    
     <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
         <span class="s">"""
         Called when initializing the classifier.
          Set default hyperparameter values here.
         """</span>
    
     <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
         <span class="s">"""
         This should fit classifier. All the "work" should be done here.
    
         Note: assert is not a good choice here and you should rather
         use try/except blog with exceptions.
          The y parameter must be set if the task is supervised learning.
         """</span>
         <span class="k">return</span> <span class="bp">self</span>
    
     <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
         <span class="s">"""Prediction Logic goes here. 
         Remember to always check if the 
         threshold attribute of your estimator is set. """</span>
         <span class="k">pass</span>
    
     <span class="k">def</span> <span class="nf">score</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
         <span class="s">""" This is only needed if the estimator is to be used with a GridSearchCV """</span>
            
     <span class="k">def</span> <span class="nf">get_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">deep</span><span class="o">=</span><span class="bp">True</span><span class="p">):</span>
         <span class="k">pass</span>

     <span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">**</span><span class="n">parameters</span><span class="p">):</span>
         <span class="k">pass</span>

</code></pre></div>    </div>
  </li>
</ol>

<p>Meta estimators are a higher order estimators that are made from other (base) estimators. They require base estimators to be provided in their constructor. The most used example of 
       meta-estimators are ensemble methods available via <code class="language-plaintext highlighter-rouge">sklearn.ensemble</code>. 
      In sklearn, each instance of a classifier (estimator) implements a corresponding meta-estimator. Custom meta-estimators can be created using the multiclass sklearn module and 
      implementing any of the <a href="http://mlwiki.org/index.php/One-vs-All_Classification">one-vs-all</a>, <a href="https://www.quora.com/Whats-an-intuitive-explanation-of-one-versus-one-classification-for-support-vector-machines">one-vs-one</a>
       or <a href="">error correcting output</a> algorithms.</p>

<p>In conclusion, always keep the following at the back of your mind when writing or working with estimators and meta-estimators:</p>

<ul>
  <li>
    <p>Constructor parameters should have default values.</p>
  </li>
  <li>
    <p>Constructor shouldn’t implement any form of logic(whether complex or not).
      Logic is best suited for the fit method.</p>
  </li>
  <li>
    <p>The <code class="language-plaintext highlighter-rouge">fit</code> method should handle all logic and return an instance of the class.</p>
  </li>
</ul>

<ol>
  <li>
    <p>Transformers</p>

    <p>Transformer objects are somewhat <code class="language-plaintext highlighter-rouge">transmutational</code> in nature. They exist to provide an interface for data modification or filtering within sklearn. Transformer objects mostly exists 
 along sides estimator objects. This means some objects have both estimator and transformation features availble to them.</p>

    <p>Like estimators, transformers do not carry out any major logic in their constructor. Instead, they  expose a <code class="language-plaintext highlighter-rouge">transform</code> method where the transformation happens. This method takes a dataset as 
 a parameter. Transformers also have a <code class="language-plaintext highlighter-rouge">fit_transform</code> or <code class="language-plaintext highlighter-rouge">fit_predict</code>(fit_predict for clustering transformers) method that both <code class="language-plaintext highlighter-rouge">fits</code> and <code class="language-plaintext highlighter-rouge">transforms</code> data in one go. Preprocessing, feature 
 selection, feature extraction and 
 dimensionality 
 reduction 
 algorithms are all provided as transformers within the sklearn.</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> from sklearn.preprocessing import Imputer

 imputer = Imputer()
    
 imputer.fit(X train)
    
 X_train = imputer.transform(X_train)
</code></pre></div>    </div>

    <p>The above block can be made better as shown below:</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> X_train = Imputer().fit(X_train).transform(X_train)
</code></pre></div>    </div>

    <p>The above line can even made more better as shown below:</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> X_train = Imputer().fit_transform(X_train)
</code></pre></div>    </div>
  </li>
  <li>
    <p>Predictors</p>

    <p>Predictor objects are able to make predictions. They’re basically estimators with a <code class="language-plaintext highlighter-rouge">predict</code> method. Predictors returns the predicted label as output. 
 Asides prediction, some predictors expose methods to benchmark various aspects of the prediction. These methods can be any of:</p>

    <ol>
      <li><code class="language-plaintext highlighter-rouge">decision_function</code> for linear models to measure the distance between samples</li>
      <li><code class="language-plaintext highlighter-rouge">score</code> to  measure the quality of the prediction. This method computes the coefficient of determination  in regression and the accuracy in classification.</li>
      <li><code class="language-plaintext highlighter-rouge">predict_proba</code> to measure class probabilities.</li>
      <li><code class="language-plaintext highlighter-rouge">predict_log_proba</code> to measure log of class probabilities.</li>
    </ol>
  </li>
  <li>
    <p>Pipelines and Feature Unions</p>

    <p>Pipelines in machine learning are chaining tools. They are used to chain processes together and follow execution from one end of the chain to the other. Sklearn provides support for pipeline
 objects that accept a list of transformers and a single estimator.</p>

    <p>The list of transformers handle intermediate steps(i.e feature extraction, dimensionality reduction, learning and making 
 predictions) and (should) expose both a <code class="language-plaintext highlighter-rouge">fit</code> and a <code class="language-plaintext highlighter-rouge">transform</code> method. The estimator only has to implement a <code class="language-plaintext highlighter-rouge">fit</code> method. Calling a pipeline, recursively fits then transforms the data set 
 till it gets to the estimator then it calls the fit method of the estimator.</p>

    <p><img src="/assets/images/pipeline.png" alt="dense matrix." /></p>

    <p>Figure 4: An example of a pipline diagram(Credits : <a href="http://karlrosaen.com/ml/learning-log/2016-06-20/">http://karlrosaen.com/ml/learning-log/2016-06-20/</a>)</p>

    <p>The final usage(features) of a pipeline depends on the attributes of the estimator in the pipeline. This means, if the estimator is a predictor pipeline, the pipeline can itself be used as a 
 predictor. 
 If the estimator is a transformer, then the pipeline is a transformer pipeline.</p>

    <p>Feature Unions are quite similar to pipelines in the sense that they are also chaining tools. However unlike pipelines, feature unions only chain together transformation processes.
 This means they accept a list of transformers as input and expose a fit method which recursively calls the base transformers <code class="language-plaintext highlighter-rouge">fit</code> methods. The main advantage of feature union objects is that 
 they can be used in place of transformers in pipelines.</p>

    <p><img src="/assets/images/pipelines.png" alt="dense matrix." /></p>

    <p>Figure 5: Example pipeline to illustrate how feature unions work. This pipeline has 3 transformers and an estimator.</p>

    <p>The <code class="language-plaintext highlighter-rouge">PCA</code> and <code class="language-plaintext highlighter-rouge">KernelPCA</code> transformers in the pipeline image above can be combined into a single FeatureUnion which can then be passed down to the SelectKBest estimator and then to the logistic 
 regression predictor.</p>

    <p><img src="/assets/images/feature_union.png" alt="dense matrix." /></p>

    <p>Figure 6: An example of a feature union in a pipeline.</p>

    <div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> from sklearn.pipeline import FeatureUnion , Pipeline 
 from sklearn.decomposition import PCA, KernelPCA 
 from sklearn.feature_selection import SelectKBest

 union = FeatureUnion([('pca', PCA()),('kpca', KernelPCA(kernel='rbf'))])

 pipeline = Pipeline([('feat union', union),
 ('feat sel', SelectKBest(k=10)),
 ('log reg', LogisticRegression(penalty='l2')) ]).fit(X train, y train).predict(X test)
</code></pre></div>    </div>
  </li>
</ol>

<h2 id="other-principles">Other Principles</h2>
<p>Asides consistency, a number of other principles the sklearn library tries to adhere by include:</p>

<ol>
  <li>
    <p>Inspection: This provides a reasonable interface to retrieve/inspect data from objects. For example, estimator hyperparameters are made to be directly accessible via public instance and their 
learnt parameters are also accessible via public instance variables with an underscore suffix</p>
  </li>
  <li>
    <p>Composition
 Blocks of code were placed together in an attempt to ensure reusability and reduce class proliferation. This, for example makes it easy to create a feature union from a sequence of transformers
  and to create a pipeline from a sequence of feature unions, transformers and an estimator without necessarily having to write new classes each time.</p>
  </li>
  <li>
    <p>Defaults:
 Sensible defaults are set in all the objects in sklearn. This provides a fallback mechanisms for variables/attributes to fall back to in case they’re not set by the user.</p>
  </li>
</ol>

<h2 id="conclusion">Conclusion</h2>
<p>Sklearn is a very interesting and powerful machine learning library. Given the fact that it covers most machine learning methods, sklearn can be a bit daunting to get through. 
   In this article, I have attempted to break down the major objects available in the library into simple understandable chunks that can be tackled at once. While, I did not cover every chunk in 
   complete detail, the resources section below provides a link to a number of articles/resources where more information can be gotten about them.</p>

<p>If you do happen to have any question or comment, do feel free to leave one below or sync up with me on <a href="https://twitter.com/__olamilekan__">twitter</a>.</p>

<h2 id="resources">Resources</h2>
<ol>
  <li><a href="https://github.com/scikit-learn/scikit-learn">https://github.com/scikit-learn/scikit-learn</a></li>
  <li><a href="http://scikit-learn.org/stable/developers/index.html">http://scikit-learn.org/stable/developers/index.html</a></li>
  <li><a href="https://stackoverflow.com/questions/46691596/why-does-sklearn-imputer-need-to-fit">Why does sklearn Imputer need to fit?</a></li>
  <li><a href="https://github.com/scikit-learn-contrib/project-template/">https://github.com/scikit-learn-contrib/project-template/</a></li>
  <li><a href="http://scikit-learn.org/stable/modules/classes.html">http://scikit-learn.org/stable/modules/classes.html</a></li>
  <li><a href="http://scikit-learn.org/stable/modules/ensemble.html">http://scikit-learn.org/stable/modules/ensemble.html</a></li>
  <li><a href="http://scikit-learn.org/dev/developers/contributing.html#rolling-your-own-estimator">http://scikit-learn.org/dev/developers/contributing.html#rolling-your-own-estimator</a></li>
  <li><a href="http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html">http://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html</a></li>
  <li><a href="http://karlrosaen.com/ml/learning-log/2016-06-20/">http://karlrosaen.com/ml/learning-log/2016-06-20/</a></li>
  <li><a href="https://arxiv.org/abs/1309.0238">https://arxiv.org/abs/1309.0238</a></li>
</ol>

  </article>

  

</div>

      </div>
    </div>

    <footer>

  <div class="wrapper">
    &copy; Copyright 2020 Olamilekan F. Wahab.
    Powered by <a href="http://jekyllrb.com/" target="_blank">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank">Unsplash</a>.

    
  </div>

</footer>


    <!-- Load jQuery -->
<script src="//code.jquery.com/jquery-1.12.4.min.js"></script>

<!-- Load Common JS -->
<script src="/assets/js/common.js"></script>


<!-- Load KaTeX -->
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css">
<script src="//cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js"></script>
<script src="/assets/js/katex.js"></script>



<!-- Load Anchor JS -->
<script src="//cdnjs.cloudflare.com/ajax/libs/anchor-js/3.2.2/anchor.min.js"></script>
<script>
  anchors.options.visible = 'always';
  anchors.add('article h2, article h3, article h4, article h5, article h6');
</script>


<!-- Include custom icon fonts -->
<link rel="stylesheet" href="/assets/css/fontawesome-all.min.css">
<link rel="stylesheet" href="/assets/css/academicons.min.css">


<!-- Google Analytics -->
<script>
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-104393656', 'auto');
ga('send', 'pageview');
</script>



  </body>

</html>
